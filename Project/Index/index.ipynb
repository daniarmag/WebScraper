{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ndvp39/CloudComputing-tirgul/blob/main/Project/Index/index.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Qu-nszRXeyxQ",
        "outputId": "1615a8be-a129-4695-d653-3f3dcb5a96b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.2.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.5)\n",
            "Collecting firebase\n",
            "  Downloading firebase-4.0.1-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from firebase) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->firebase) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->firebase) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->firebase) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->firebase) (2024.2.2)\n",
            "Installing collected packages: firebase\n",
            "Successfully installed firebase-4.0.1\n",
            "Requirement already satisfied: firebase-admin in /usr/local/lib/python3.10/dist-packages (5.3.0)\n",
            "Requirement already satisfied: cachecontrol>=0.12.6 in /usr/local/lib/python3.10/dist-packages (from firebase-admin) (0.14.0)\n",
            "Requirement already satisfied: google-api-python-client>=1.7.8 in /usr/local/lib/python3.10/dist-packages (from firebase-admin) (2.84.0)\n",
            "Requirement already satisfied: google-cloud-storage>=1.37.1 in /usr/local/lib/python3.10/dist-packages (from firebase-admin) (2.8.0)\n",
            "Requirement already satisfied: google-api-core[grpc]<3.0.0dev,>=1.22.1 in /usr/local/lib/python3.10/dist-packages (from firebase-admin) (2.11.1)\n",
            "Requirement already satisfied: google-cloud-firestore>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from firebase-admin) (2.11.1)\n",
            "Requirement already satisfied: requests>=2.16.0 in /usr/local/lib/python3.10/dist-packages (from cachecontrol>=0.12.6->firebase-admin) (2.31.0)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from cachecontrol>=0.12.6->firebase-admin) (1.0.8)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]<3.0.0dev,>=1.22.1->firebase-admin) (1.63.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]<3.0.0dev,>=1.22.1->firebase-admin) (3.20.3)\n",
            "Requirement already satisfied: google-auth<3.0.dev0,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]<3.0.0dev,>=1.22.1->firebase-admin) (2.27.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]<3.0.0dev,>=1.22.1->firebase-admin) (1.62.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]<3.0.0dev,>=1.22.1->firebase-admin) (1.48.2)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.7.8->firebase-admin) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.7.8->firebase-admin) (0.1.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.7.8->firebase-admin) (4.1.1)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-firestore>=2.1.0->firebase-admin) (2.3.3)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-firestore>=2.1.0->firebase-admin) (1.23.0)\n",
            "Requirement already satisfied: google-resumable-media>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage>=1.37.1->firebase-admin) (2.7.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]<3.0.0dev,>=1.22.1->firebase-admin) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]<3.0.0dev,>=1.22.1->firebase-admin) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]<3.0.0dev,>=1.22.1->firebase-admin) (4.9)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-resumable-media>=2.3.2->google-cloud-storage>=1.37.1->firebase-admin) (1.5.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1dev,>=0.15.0->google-api-python-client>=1.7.8->firebase-admin) (3.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.16.0->cachecontrol>=0.12.6->firebase-admin) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.16.0->cachecontrol>=0.12.6->firebase-admin) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.16.0->cachecontrol>=0.12.6->firebase-admin) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.16.0->cachecontrol>=0.12.6->firebase-admin) (2024.2.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]<3.0.0dev,>=1.22.1->firebase-admin) (0.6.0)\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "!pip install requests beautifulsoup4\n",
        "!pip install firebase\n",
        "!pip install firebase-admin\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "from nltk.stem import PorterStemmer\n",
        "from bs4 import BeautifulSoup\n",
        "from collections import defaultdict\n",
        "from firebase_admin import credentials\n",
        "from firebase_admin import firestore\n",
        "import firebase_admin\n",
        "import requests\n",
        "import re\n",
        "import json\n",
        "import os\n",
        "'''\n",
        "\n",
        "# activate only if run this file directly and not from searchEngine\n",
        "#!git clone \"https://github.com/ndvp39/CloudComputing-tirgul.git\"\n"
      ],
      "metadata": {
        "id": "fyPfzgti9aB2",
        "outputId": "8cf83d45-45c4-48c7-cec8-a80f2539d5fb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'CloudComputing-tirgul'...\n",
            "remote: Enumerating objects: 4396, done.\u001b[K\n",
            "remote: Counting objects: 100% (1137/1137), done.\u001b[K\n",
            "remote: Compressing objects: 100% (539/539), done.\u001b[K\n",
            "remote: Total 4396 (delta 779), reused 862 (delta 564), pack-reused 3259\u001b[K\n",
            "Receiving objects: 100% (4396/4396), 25.84 MiB | 18.90 MiB/s, done.\n",
            "Resolving deltas: 100% (1773/1773), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "pMW9CHqNe4eZ"
      },
      "outputs": [],
      "source": [
        "# Function to extract text from a webpage\n",
        "def get_page_text(url):\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "        return soup.get_text()\n",
        "    except Exception as e:\n",
        "        return \"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to extract links from a webpage\n",
        "def get_links(url):\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "        links = [link.get('href') for link in soup.find_all('a', href=True)]\n",
        "        return links\n",
        "    except Exception as e:\n",
        "        print(\"Error:\", e)\n",
        "        return []"
      ],
      "metadata": {
        "id": "t7M-PSVLZbNF"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "rn3hNM37pgNk"
      },
      "outputs": [],
      "source": [
        "# Removes stop words from the given text - done to skip nonimportant words.\n",
        "def remove_stop_words(text):\n",
        "  stop_words = {'ha','thi','skip','-','&', 'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"}\n",
        "\n",
        "  words = [word for word in text if word.lower() not in stop_words]\n",
        "  return words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "L2vktA22phqW"
      },
      "outputs": [],
      "source": [
        "# Trimming unnecessary chars.\n",
        "def trim_words(words):\n",
        "    cleaned_words = [word.rstrip(\",.\\\\/?!\") for word in words]\n",
        "    return cleaned_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "veWH8BZgpk8l"
      },
      "outputs": [],
      "source": [
        "# Applies stemming to a list of words.\n",
        "def apply_stemming(words):\n",
        "    stemmer = PorterStemmer()\n",
        "    stemmed_words = [stemmer.stem(word) for word in words]\n",
        "    return stemmed_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "sbxUcYpEn2bl"
      },
      "outputs": [],
      "source": [
        "# Function to create index database.\n",
        "def create_index(url):\n",
        "    index = defaultdict(list)\n",
        "    visited = set()\n",
        "    queue = [url]\n",
        "    loop = 0\n",
        "    # Limit the search depth.\n",
        "    while queue and loop < 40:\n",
        "        loop+=1\n",
        "        current_url = queue.pop(0)\n",
        "        if current_url in visited:\n",
        "            continue\n",
        "        visited.add(current_url)\n",
        "        text = get_page_text(current_url)\n",
        "        words = remove_stop_words(text.split())\n",
        "        words = trim_words(words)\n",
        "        words = apply_stemming(words)\n",
        "        for word in words:\n",
        "            index[word].append(current_url)\n",
        "        links = get_links(current_url)\n",
        "        for link in links:\n",
        "            if link.startswith(url) and link not in visited:\n",
        "                queue.append(link)\n",
        "    return index"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This creates a dict with an id for each link and word counter based on the index that was returned in create_index.\n",
        "def update_dict(word, link):\n",
        "    global link_ids\n",
        "    if link not in link_ids:\n",
        "        link_ids[link] = len(link_ids) + 1\n",
        "    link_id = link_ids[link]\n",
        "    if link not in index[word]:\n",
        "        index[word][link] = {'id': link_id, 'counter': 0}\n",
        "    index[word][link]['counter'] += 1"
      ],
      "metadata": {
        "id": "PB0kfsUP5gs4"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "btytvwAQe3NN"
      },
      "outputs": [],
      "source": [
        "# Ranking the words based on how many times they appeared.\n",
        "def create_ranked_words(index):\n",
        "    sorted_dict = {}\n",
        "    counter_for_each_word = 0\n",
        "    for word, links in index.items():\n",
        "        for link in links.keys():\n",
        "            counter_for_each_word += index[word][link]['counter']\n",
        "        sorted_dict[word] = counter_for_each_word\n",
        "        counter_for_each_word = 0\n",
        "    # Sort the dictionary by counts in descending order\n",
        "    sorted_dict = {k: v for k, v in sorted(sorted_dict.items(), key=lambda item: item[1], reverse=True)}\n",
        "    ranked_dict = {}\n",
        "    rank = 1\n",
        "    for word, counter in sorted_dict.items():\n",
        "        # highest rank = biggest counter\n",
        "        ranked_dict[word] = {'rank': rank, 'counter': counter}\n",
        "        rank += 1\n",
        "    return ranked_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "3xis_RWStxOu"
      },
      "outputs": [],
      "source": [
        "# Creates a dict that can fit into the firestore format.\n",
        "def create_data_for_db(final_index):\n",
        "    data_list = []\n",
        "    for word, doc_ids in final_index.items():\n",
        "        term_data = {\n",
        "            'term': word,\n",
        "            'DocId': doc_ids\n",
        "        }\n",
        "        data_list.append(term_data)\n",
        "    return data_list"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# In case we want to generate a json file and upload it to db and not directly from code. ## NOT IN USE ##\n",
        "def generate_json_file(data_list, is_desktop):\n",
        "    if is_desktop:\n",
        "      filepath = os.path.join(os.path.dirname(os.path.abspath(__file__)), \"indexDb.json\")\n",
        "    else:\n",
        "      filepath = \"/content/drive/My Drive/CloudComputing/project/indexDb.json\"\n",
        "    with open(filepath, \"w\") as json_file:\n",
        "        json.dump(data_list, json_file, indent = 2)"
      ],
      "metadata": {
        "id": "izeILoTI5tCA"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prints the content from data base.\n",
        "def print_collection_from_db(collection_name):\n",
        "    collection_ref = db.collection(collection_name)\n",
        "    docs = collection_ref.get()\n",
        "    i = 0\n",
        "    for doc in docs:\n",
        "        term = doc.to_dict()['term']\n",
        "        print(f\"{i} -- Document ID: {doc.id}, Data: {term}\")\n",
        "        i += 1"
      ],
      "metadata": {
        "id": "WV_K6sn95xK1"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Uploads the index to the db.\n",
        "def upload_to_db(data_list, collection_name):\n",
        "  try:\n",
        "    for data in data_list:\n",
        "        doc_ref = db.collection(collection_name).add(data)\n",
        "    print(\"All documents uploaded successfully.\")\n",
        "  except Exception as e:\n",
        "      print(\"Error:\", e)"
      ],
      "metadata": {
        "id": "xaHHTntkxRUl"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gets the index from db, used in searchEngine and in chatbot files.\n",
        "def get_index_from_db(db_con = None):\n",
        "    dcon = db_con if db_con is not None else db\n",
        "    imported_dict = {}\n",
        "    collection_ref = dcon.collection(db_collection_name)\n",
        "    docs = collection_ref.get()\n",
        "    for doc in docs:\n",
        "        # Checks if the doc is indeed in the db.\n",
        "        if doc.exists:\n",
        "            term = doc.to_dict()['term']\n",
        "            doc_id = doc.to_dict()['DocId']\n",
        "            imported_dict[term] = doc_id\n",
        "    return imported_dict"
      ],
      "metadata": {
        "id": "_FwisRME2Fxd"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Main section for index.ipynb"
      ],
      "metadata": {
        "id": "VWRdzavL_2ob"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "website_url = 'https://www.redhat.com/en'\n",
        "db_collection_name = \"PantherIndex\"\n",
        "\n",
        "# createing the index, only once.\n",
        "'''\n",
        "link_ids = {}\n",
        "index_db = create_index(website_url)\n",
        "index = defaultdict(dict)\n",
        "\n",
        "for word, links in index_db.items():\n",
        "    for link in links:\n",
        "        update_dict(word, link)\n",
        "\n",
        "ranked_words = create_ranked_words(index)\n",
        "chosen_words = list(ranked_words.keys())[:110]\n",
        "final_index = {word:index[word] for word in chosen_words}\n",
        "data_list_for_db = create_data_for_db(final_index)\n",
        "'''\n",
        "\n",
        "# db connection.\n",
        "cred = credentials.Certificate(\"/content/CloudComputing-tirgul/Project/Json/sak.json\")\n",
        "if not firebase_admin._apps:\n",
        "  firebase_admin.initialize_app(cred)\n",
        "db = firestore.client()\n",
        "\n",
        "#upload_to_db(data_list_for_db, db_collection_name)\n",
        "#print_collection_from_db(db_collection_name)"
      ],
      "metadata": {
        "id": "PNgxBfn814Zm",
        "outputId": "b36b42ee-12f4-4e72-c0bf-3399c0e20872",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 -- Document ID: 1I7E4scQgGGi9yEWFNyw, Data: product\n",
            "1 -- Document ID: 1p0L91u9gVbyGecsAWg4, Data: customerscustom\n",
            "2 -- Document ID: 29BUQd0VvKWHv9lxbnsp, Data: vs\n",
            "3 -- Document ID: 2j8wawISTREjaacyaoIt, Data: foundat\n",
            "4 -- Document ID: 4zWdmExD4XPQVrbDR34d, Data: cloud\n",
            "5 -- Document ID: 5MJ9fuWHqKJvbIlOZ0gZ, Data: event\n",
            "6 -- Document ID: 5l9HK6CNBRrcX7AX1ELT, Data: certifi\n",
            "7 -- Document ID: 5lcuhiGz1Mq729K1ACyf, Data: sourc\n",
            "8 -- Document ID: 72innQemNJirQLcwwwU1, Data: across\n",
            "9 -- Document ID: 7GMBHOzvHTwqiaFOPY0X, Data: relat\n",
            "10 -- Document ID: 7ay2yQBORiRjiHZ7D2FV, Data: ai\n",
            "11 -- Document ID: 7vZvzO7uRVg5m62y4PVv, Data: contact\n",
            "12 -- Document ID: 8VHpUJRkx8dLlp3GIRkw, Data: linux\n",
            "13 -- Document ID: 93HTXMqSc99P64Capz0j, Data: marketplac\n",
            "14 -- Document ID: 9QpuC9KZmkhpzSRbWApL, Data: new\n",
            "15 -- Document ID: 9VvPZoeTDPPaB4zx216a, Data: subscript\n",
            "16 -- Document ID: 9dJ1SobS1RBV1nASIaD2, Data: success\n",
            "17 -- Document ID: 9zKWSoX9Yln6ro5YLbOp, Data: managementr\n",
            "18 -- Document ID: A6WrfGihFdGAw1Pijg5i, Data: sellr\n",
            "19 -- Document ID: AT9dShGiGdumpWp1vkhB, Data: learn\n",
            "20 -- Document ID: BuYIH9T8j6JsYyU6o5nT, Data: architect\n",
            "21 -- Document ID: By7JePwKjC3Ib82h77lI, Data: specialist\n",
            "22 -- Document ID: C3mKiJqW0YkkedVwVdVr, Data: comput\n",
            "23 -- Document ID: CbUFmTg3aMnHygjnVtG6, Data: hybrid\n",
            "24 -- Document ID: DToAgGZkL6TSGDfnufYc, Data: select\n",
            "25 -- Document ID: DbGiJ36St9fwZddWTWRm, Data: explor\n",
            "26 -- Document ID: EFQpFBG0lqJyroq4VbQk, Data: use\n",
            "27 -- Document ID: FtIAxgBqDjppXPvyOJY2, Data: compani\n",
            "28 -- Document ID: GOOQV1aqjHT8nUfF2mRM, Data: scale\n",
            "29 -- Document ID: Hhh79iZ3K2kmBjFWSXE4, Data: technolog\n",
            "30 -- Document ID: I528LI19PgKpAyAAwL72, Data: commun\n",
            "31 -- Document ID: Jo9Rwg2jLXRcwKwjTxKQ, Data: partnerspartn\n",
            "32 -- Document ID: KUcvlfpf17pqWnolP9fJ, Data: engin\n",
            "33 -- Document ID: KXd6iAyrUHKk9FOlvlIB, Data: sector\n",
            "34 -- Document ID: KuC6qoKfLaW4Yf4Oc7uG, Data: tri\n",
            "35 -- Document ID: LhGuVxUz1Xjz9sgmxyns, Data: catalogfind\n",
            "36 -- Document ID: Lpc7wcESIfS6o1gv48cb, Data: provid\n",
            "37 -- Document ID: MRNU48yCJTSSWArAw0Ie, Data: supportdocumentationsupport\n",
            "38 -- Document ID: MW76Y4LkJMwXjmfu9BkG, Data: network\n",
            "39 -- Document ID: MkU4VPKP5K8Z9VKpoJg0, Data: storecontact\n",
            "40 -- Document ID: MwagBb6wG9iZeDJe84Ia, Data: custom\n",
            "41 -- Document ID: N8ffRiZpxEMYIY6EPJ08, Data: servic\n",
            "42 -- Document ID: P0N4VhBRdsgAjglDsOvI, Data: ansibl\n",
            "43 -- Document ID: PGuTOjIPaZrawtV97YeL, Data: openshift\n",
            "44 -- Document ID: PWJAykH2Hv2XOWnQ3qMp, Data: data\n",
            "45 -- Document ID: PcgSnGiYm2SFJEs3iVi5, Data: certif\n",
            "46 -- Document ID: Pjg8vVZWdFdHn7bji9Gu, Data: supportbecom\n",
            "47 -- Document ID: Q7yIRp3thzRCo6755bfX, Data: work\n",
            "48 -- Document ID: Q9H3cnzew4RJMLlMwTM2, Data: applic\n",
            "49 -- Document ID: QEV5uxfN3MaZejiFtyao, Data: newsroom\n",
            "50 -- Document ID: Rohez2ToqRus435GbZdB, Data: trial\n",
            "51 -- Document ID: SPSiQPvfWYBrhZooJGxc, Data: need\n",
            "52 -- Document ID: STe5fuf5yosBPl7MVaOB, Data: environ\n",
            "53 -- Document ID: StgLT1RWGB7PYzsBd4j8, Data: industri\n",
            "54 -- Document ID: UgQf6IFN9MJFEXzQ05p1, Data: triallearn\n",
            "55 -- Document ID: WYabCjPJV81gQwsz1CGP, Data: open\n",
            "56 -- Document ID: XjMYHwNckMNOO3dWqMdh, Data: partner\n",
            "57 -- Document ID: bT1GByubQ8jdV7TYwgsL, Data: system\n",
            "58 -- Document ID: bk8VSTmsDaagMai01nL4, Data: us\n",
            "59 -- Document ID: cRZbxbReTusPVPZyycu9, Data: cloud-n\n",
            "60 -- Document ID: cz42bu47ba8TBu63YalJ, Data: blog\n",
            "61 -- Document ID: deLr1WppYYJV4ISAffuc, Data: kubernet\n",
            "62 -- Document ID: eLP8OOn77ay4sHnbAdMl, Data: devop\n",
            "63 -- Document ID: eS3DMoj68b38cmhKUOUt, Data: make\n",
            "64 -- Document ID: eUuS8A2LPJpYKpAZ6c7W, Data: manag\n",
            "65 -- Document ID: ftPra3kQHR9QTcCDiIeI, Data: privaci\n",
            "66 -- Document ID: gma4bhe78XnLpB3nRSb1, Data: infrastructur\n",
            "67 -- Document ID: iU3ueHqXW0ORzjHrQ744, Data: train\n",
            "68 -- Document ID: iWEPcDC1BuvDx53pdKpo, Data: connect\n",
            "69 -- Document ID: ifHBknVxIckDbFcmn7xP, Data: resourc\n",
            "70 -- Document ID: jAPUHxET4nXpaBdimy9Q, Data: solut\n",
            "71 -- Document ID: jAvjwfg2SPFjRTdwg89C, Data: rest\n",
            "72 -- Document ID: jD8Sopple1tleBnojk1X, Data: innov\n",
            "73 -- Document ID: jKm6y5ntV3fGUPq8Jjz0, Data: contain\n",
            "74 -- Document ID: kDzyfMwhV2yBTadjHy1i, Data: edg\n",
            "75 -- Document ID: kJn5cZSUvVYEde5JUMsw, Data: administr\n",
            "76 -- Document ID: kcuQPlVfDu5RDtgboaBs, Data: partnerfor\n",
            "77 -- Document ID: l7yRzLkX1bopHDfCVAA7, Data: search\n",
            "78 -- Document ID: m6QPiovqDrgLa4JaFu75, Data: deploy\n",
            "79 -- Document ID: m6cfAZh39ZbDnjsNaVNL, Data: red\n",
            "80 -- Document ID: miY2TSSYAQ3vnsyqtzqf, Data: develop\n",
            "81 -- Document ID: mtI7L4DPxf1AYG4QKLem, Data: platform\n",
            "82 -- Document ID: n0rsF1NcxLA4zFrbza08, Data: buy\n",
            "83 -- Document ID: nC7kIdxR23oxb1nlqw94, Data: organ\n",
            "84 -- Document ID: oIF0eqFz5AZyXhW3PvzX, Data: hat\n",
            "85 -- Document ID: oMQJ6FPoqp2DRk3AOFbB, Data: consult\n",
            "86 -- Document ID: qqFltPN2Yk10WIyxTDLK, Data: support\n",
            "87 -- Document ID: rF5X0C8oR8pc6Ac7tV2S, Data: casessubscript\n",
            "88 -- Document ID: rLZwiEsDu6C4B5B0YFQs, Data: salesstart\n",
            "89 -- Document ID: rNu3EXlcwIfh84L8E02E, Data: build\n",
            "90 -- Document ID: rXeNd5CdutSpcklO6QBv, Data: see\n",
            "91 -- Document ID: rb6Dy2RrUNWEbWWWd5F9, Data: featur\n",
            "92 -- Document ID: reCQCzE9mftaC3tOAT1H, Data: oper\n",
            "93 -- Document ID: rzVT5fTJZ9MFPgYsVWqH, Data: api\n",
            "94 -- Document ID: t6FFPBo5ev2w6gMHa3FG, Data: modern\n",
            "95 -- Document ID: tVFMoMHgn8Y6g0nQCEt2, Data: healthcar\n",
            "96 -- Document ID: u1SxCoYP1IDfWnoyMRF2, Data: help\n",
            "97 -- Document ID: u7AlyNlSGS3oQhPZr6un, Data: model\n",
            "98 -- Document ID: uycpkkiwHw5cuxQMS83L, Data: enterpris\n",
            "99 -- Document ID: vJdmbqKo4tBguSvS62m0, Data: autom\n",
            "100 -- Document ID: vLrXnuu4eldwR3doe1Nx, Data: access\n",
            "101 -- Document ID: wBFFDUE2fgUNZyI6CqF1, Data: secur\n",
            "102 -- Document ID: ww3J7pH62cKDraxEVlGG, Data: portalpartn\n",
            "103 -- Document ID: xPMdQSwnErmmhAKi5dXD, Data: topic\n",
            "104 -- Document ID: xWXD7xYrGIlaeyf22yBa, Data: integr\n",
            "105 -- Document ID: xw6knqC9AYa2xzd73WTI, Data: commit\n",
            "106 -- Document ID: y5iLf2oWjZwdCa8ByquK, Data: stori\n",
            "107 -- Document ID: yAsBODL52S4uZvNcYK0T, Data: ecosystem\n",
            "108 -- Document ID: yZqB3E9Xvm8DWMiZ4Kla, Data: articl\n",
            "109 -- Document ID: zWnhZiKCvelncOs1PUsg, Data: legal\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}