{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ndvp39/CloudComputing-tirgul/blob/main/Project/Index/index.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qu-nszRXeyxQ"
      },
      "outputs": [],
      "source": [
        "!pip install requests beautifulsoup4\n",
        "!pip install firebase\n",
        "!pip install firebase-admin"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from bs4 import BeautifulSoup\n",
        "from collections import defaultdict\n",
        "from firebase_admin import credentials\n",
        "from firebase_admin import firestore\n",
        "import firebase_admin\n",
        "import requests\n",
        "import re\n",
        "import json\n",
        "import os\n",
        "\n",
        "# activate only if run this file directly and not from searchEngine\n",
        "#!git clone \"https://github.com/ndvp39/CloudComputing-tirgul.git\"\n"
      ],
      "metadata": {
        "id": "fyPfzgti9aB2",
        "outputId": "9bb9441f-74ba-408c-a814-98f95a239ce3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'CloudComputing-tirgul' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pMW9CHqNe4eZ"
      },
      "outputs": [],
      "source": [
        "# Function to extract text from a webpage\n",
        "def get_page_text(url):\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "        return soup.get_text()\n",
        "    except Exception as e:\n",
        "        return \"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to extract links from a webpage\n",
        "def get_links(url):\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "        links = [link.get('href') for link in soup.find_all('a', href=True)]\n",
        "        return links\n",
        "    except Exception as e:\n",
        "        print(\"Error:\", e)\n",
        "        return []"
      ],
      "metadata": {
        "id": "t7M-PSVLZbNF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rn3hNM37pgNk"
      },
      "outputs": [],
      "source": [
        "def remove_stop_words(text):\n",
        "  stop_words = {'a','as','ha','thi','an', 'the', 'and', 'is', 'are', 'or', 'in', 'on', 'at','skip','-','them','they','than','she',',','.','&','for','what'}\n",
        "  words = [word for word in text if word.lower() not in stop_words]\n",
        "  return words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L2vktA22phqW"
      },
      "outputs": [],
      "source": [
        "def trim_words(words):\n",
        "    cleaned_words = [word.rstrip(\",.\\\\/\") for word in words]\n",
        "    return cleaned_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "veWH8BZgpk8l"
      },
      "outputs": [],
      "source": [
        "def apply_stemming(words):\n",
        "    stemmer = PorterStemmer()\n",
        "    stemmed_words = [stemmer.stem(word) for word in words]\n",
        "    return stemmed_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sbxUcYpEn2bl"
      },
      "outputs": [],
      "source": [
        "# Function to create index database\n",
        "def create_index(url):\n",
        "    index = defaultdict(list)\n",
        "    visited = set()\n",
        "    queue = [url]\n",
        "    loop = 0\n",
        "    while queue and loop < 40:\n",
        "        loop+=1\n",
        "        current_url = queue.pop(0)\n",
        "        if current_url in visited:\n",
        "            continue\n",
        "\n",
        "        visited.add(current_url)\n",
        "        text = get_page_text(current_url)\n",
        "        words = remove_stop_words(text.split())\n",
        "        words = trim_words(words)\n",
        "        words = apply_stemming(words)\n",
        "\n",
        "        for word in words:\n",
        "            index[word].append(current_url)\n",
        "\n",
        "        links = get_links(current_url)\n",
        "        for link in links:\n",
        "            if link.startswith(url) and link not in visited:\n",
        "                queue.append(link)\n",
        "    return index"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def update_dict(word, link):\n",
        "    global link_ids\n",
        "    if link not in link_ids:\n",
        "        link_ids[link] = len(link_ids) + 1\n",
        "    link_id = link_ids[link]\n",
        "    if link not in index[word]:\n",
        "        index[word][link] = {'id': link_id, 'counter': 0}\n",
        "    index[word][link]['counter'] += 1"
      ],
      "metadata": {
        "id": "PB0kfsUP5gs4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "btytvwAQe3NN"
      },
      "outputs": [],
      "source": [
        "def create_ranked_words(index):\n",
        "    sorted_dict = {}\n",
        "    counter_for_each_word = 0\n",
        "    for word, links in index.items():\n",
        "        for link in links.keys():\n",
        "            counter_for_each_word += index[word][link]['counter']\n",
        "        sorted_dict[word] = counter_for_each_word\n",
        "        counter_for_each_word = 0\n",
        "    sorted_dict = {k: v for k, v in sorted(sorted_dict.items(), key=lambda item: item[1], reverse=True)}\n",
        "    ranked_dict = {}\n",
        "    rank = 1\n",
        "    for word, counter in sorted_dict.items():\n",
        "        ranked_dict[word] = {'rank': rank, 'counter': counter}\n",
        "        rank += 1\n",
        "    return ranked_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3xis_RWStxOu"
      },
      "outputs": [],
      "source": [
        "def create_data_for_db(final_index):\n",
        "    data_list = []\n",
        "    for word, doc_ids in final_index.items():\n",
        "        term_data = {\n",
        "            'term': word,\n",
        "            'DocId': doc_ids\n",
        "        }\n",
        "        data_list.append(term_data)\n",
        "    return data_list"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_json_file(data_list, is_desktop):\n",
        "    if is_desktop:\n",
        "      filepath = os.path.join(os.path.dirname(os.path.abspath(__file__)), \"indexDb.json\")\n",
        "    else:\n",
        "      filepath = \"/content/drive/My Drive/CloudComputing/project/indexDb.json\"\n",
        "    with open(filepath, \"w\") as json_file:\n",
        "        json.dump(data_list, json_file, indent = 2)"
      ],
      "metadata": {
        "id": "izeILoTI5tCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_collection_from_db(collection_name):\n",
        "    collection_ref = db.collection(collection_name)\n",
        "    docs = collection_ref.get()\n",
        "    i = 0\n",
        "    for doc in docs:\n",
        "        term = doc.to_dict()['term']\n",
        "        print(f\"{i} -- Document ID: {doc.id}, Data: {term}\")\n",
        "        i += 1"
      ],
      "metadata": {
        "id": "WV_K6sn95xK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def upload_to_db(data_list, collection_name):\n",
        "  try:\n",
        "    for data in data_list:\n",
        "        doc_ref = db.collection(collection_name).add(data)\n",
        "    print(\"All documents uploaded successfully.\")\n",
        "  except Exception as e:\n",
        "      print(\"Error:\", e)"
      ],
      "metadata": {
        "id": "xaHHTntkxRUl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_index_from_db(db_con = None):\n",
        "    dcon = db_con if db_con is not None else db\n",
        "    imported_dict = {}\n",
        "    collection_ref = dcon.collection(db_collection_name)\n",
        "    docs = collection_ref.get()\n",
        "    for doc in docs:\n",
        "        if doc.exists:\n",
        "            term = doc.to_dict()['term']\n",
        "            doc_id = doc.to_dict()['DocId']\n",
        "            imported_dict[term] = doc_id\n",
        "    return imported_dict"
      ],
      "metadata": {
        "id": "_FwisRME2Fxd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "website_url = 'https://www.redhat.com/en'\n",
        "db_collection_name = \"PantherIndex\"\n",
        "\n",
        "# createing the index, only once\n",
        "'''\n",
        "link_ids = {}\n",
        "index_db = create_index(website_url)\n",
        "index = defaultdict(dict)\n",
        "\n",
        "for word, links in index_db.items():\n",
        "    for link in links:\n",
        "        update_dict(word, link)\n",
        "\n",
        "ranked_words = create_ranked_words(index)\n",
        "chosen_words = list(ranked_words.keys())[:110]\n",
        "final_index = {word:index[word] for word in chosen_words}\n",
        "data_list_for_db = create_data_for_db(final_index)\n",
        "'''\n",
        "\n",
        "cred = credentials.Certificate(\"/content/CloudComputing-tirgul/Project/Json/sak.json\")\n",
        "if not firebase_admin._apps:\n",
        "  firebase_admin.initialize_app(cred)\n",
        "db = firestore.client()\n",
        "\n",
        "#upload_to_db(data_list_for_db, db_collection_name)\n",
        "#print_collection_from_db(db_collection_name)"
      ],
      "metadata": {
        "id": "PNgxBfn814Zm"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}